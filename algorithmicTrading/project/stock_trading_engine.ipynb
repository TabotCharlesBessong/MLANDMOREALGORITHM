{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.regression.rolling import RollingOLS\n",
    "import pandas_datareader as web\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import yfinance as yf\n",
    "import pandas_ta\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Downloading dataset and organising data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500 = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')[0]\n",
    "sp500.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500['Symbol'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500['Symbol'] = sp500['Symbol'].str.replace('.','-')\n",
    "symbols_list = sp500['Symbol'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date = '2023-09-27'\n",
    "\n",
    "start_date = pd.to_datetime(end_date) - pd.DateOffset(365*8)\n",
    "\n",
    "data = yf.download(tickers=symbols_list,start=start_date,end=end_date).stack()\n",
    "data.index.names = ['date','ticker']\n",
    "data.columns = data.columns.str.lower()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Garmman Klass Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['german_klass_vol'] = ((np.log(data['high'])-np.log(data['low']))**2)/2-(2*np.log(2)-1)*((np.log(data['adj close'])-np.log(data['open']))**2)\n",
    "\n",
    "data['rsi'] = data.groupby(level=1)['adj close'].transform(lambda x: pandas_ta.rsi(close=x,length=20))\n",
    "\n",
    "data['bb_low'] = data.groupby(level=1)['adj close'].transform(lambda x: pandas_ta.bbands(close=np.log1p(x),length=20).iloc[:,0])\n",
    "\n",
    "data['bb_mid'] = data.groupby(level=1)['adj close'].transform(lambda x: pandas_ta.bbands(close=np.log1p(x), length=20).iloc[:,1])\n",
    "                                                          \n",
    "data['bb_high'] = data.groupby(level=1)['adj close'].transform(lambda x: pandas_ta.bbands(close=np.log1p(x), length=20).iloc[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_atr(stock_data):\n",
    "  atr = pandas_ta.atr(high=stock_data['high'],low=stock_data['low'],close=stock_data['close'],length=14)\n",
    "  \n",
    "  return atr.sub(atr.mean()).div(atr.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['atr'] = data.groupby(level=1,group_keys=False).apply(compute_atr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_macd(close):\n",
    "  macd = pandas_ta.macd(close=close,length=20).iloc[:,0]\n",
    "  return macd.sub(macd.mean()).div(macd.std())\n",
    "\n",
    "data['macd'] = data.groupby(level=1,group_keys=False)['adj close'].apply(compute_macd)\n",
    "\n",
    "data['dollar_volume'] = (data['adj close'] * data['volume']) / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[900000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Aggregate to monthly level and filter top 150 most liquid stocks for each month.\n",
    "\n",
    "* To reduce training time and experiment with features and strategies, we convert the business-daily data to month-end frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_cols = [c for c in data.columns.unique(0) if c not in ['dollar_volume','volume','open','high','low','close']]\n",
    "\n",
    "data = (pd.concat([data.unstack('ticker')['dollar_volume'].resample('M').mean().stack('ticker').to_frame('dollar_volume'),data.unstack()[last_cols].resample('M').last().stack('ticker')],axis=1)).dropna()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Calculate 5-year rolling average of dollar volume for each stocks before filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['dollar_volume'] = (data.loc[:,'dollar_volume'].unstack('ticker').rolling(5*12,min_periods=12).mean().stack())\n",
    "\n",
    "data['dollar_vol_rank'] = (data.groupby('date')['dollar_volume'].rank(ascending=False))\n",
    "\n",
    "data = data[data['dollar_vol_rank']<150].drop(['dollar_volume', 'dollar_vol_rank'], axis=1)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate Monthly Returns for different time horizons as features.\n",
    "\n",
    "* To capture time series dynamics that reflect, for example, momentum patterns, we compute historical returns using the method .pct_change(lag), that is, returns over various monthly periods as identified by lags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_returns(df):\n",
    "\n",
    "    outlier_cutoff = 0.005\n",
    "\n",
    "    lags = [1, 2, 3, 6, 9, 12]\n",
    "\n",
    "    for lag in lags:\n",
    "\n",
    "        df[f'return_{lag}m'] = (df['adj close']\n",
    "                              .pct_change(lag)\n",
    "                              .pipe(lambda x: x.clip(lower=x.quantile(outlier_cutoff),\n",
    "                                                     upper=x.quantile(1-outlier_cutoff)))\n",
    "                              .add(1)\n",
    "                              .pow(1/lag)\n",
    "                              .sub(1))\n",
    "    return df\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data.groupby(level=1, group_keys=False).apply(calculate_returns).dropna\n",
    "data = data.groupby(level=1,group_keys=False).apply(calculate_returns)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
